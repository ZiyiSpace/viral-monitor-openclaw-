/**
 * AI å†…å®¹å¤„ç†æ¨¡å—
 * æ”¯æŒå¤šç§ AI æä¾›å•†è¿›è¡Œå†…å®¹ç¿»è¯‘ã€æ”¹å†™å’Œæ ¼å¼åŒ–
 */

export interface AIProcessorConfig {
  provider: 'glm' | 'anthropic' | 'openai';
  apiKey: string;
  baseUrl?: string;
}

export interface ProcessedContent {
  original: {
    title: string;
    text: string;
    url: string;
    author: string;
  };
  xiaohongshu: {
    title: string;
    content: string;
    tags: string[];
  };
  douyin: {
    title: string;
    content: string;
    tags: string[];
  };
  kuaishou: {
    title: string;
    content: string;
    tags: string[];
  };
  recommendationScore: number; // 0-100
}

/**
 * AI å†…å®¹å¤„ç†å™¨
 */
export class AIContentProcessor {
  private config: AIProcessorConfig;

  constructor(config: AIProcessorConfig) {
    this.config = config;
  }

  /**
   * å¤„ç†å•æ¡å†…å®¹
   */
  async processContent(rawContent: any): Promise<ProcessedContent> {
    const prompt = this.buildPrompt(rawContent);

    let aiResponse: string;
    if (this.config.provider === 'glm') {
      aiResponse = await this.callGLM(prompt);
    } else if (this.config.provider === 'anthropic') {
      aiResponse = await this.callAnthropic(prompt);
    } else {
      throw new Error(`Unsupported provider: ${this.config.provider}`);
    }

    return this.parseResponse(aiResponse, rawContent);
  }

  /**
   * æ‰¹é‡å¤„ç†å†…å®¹
   */
  async processBatch(contents: any[], onProgress?: (current: number, total: number) => void): Promise<ProcessedContent[]> {
    const results: ProcessedContent[] = [];

    for (let i = 0; i < contents.length; i++) {
      const processed = await this.processContent(contents[i]);
      results.push(processed);

      if (onProgress) {
        onProgress(i + 1, contents.length);
      }
    }

    return results;
  }

  /**
   * æ„å»º AI æç¤ºè¯
   */
  private buildPrompt(content: any): string {
    const platform = content.platform;
    const text = content.text || '';
    const author = content.author?.username || '';
    const metrics = content.metrics || {};
    const url = content.url || '';

    // æå–æ ‡é¢˜ï¼ˆReddit æœ‰ titleï¼ŒTwitter éœ€è¦ä» text æå–ï¼‰
    const title = content.title || text.split('\n')[0].substring(0, 50);

    return `è¯·å°†ä»¥ä¸‹${platform}å†…å®¹æ”¹å†™ä¸ºé€‚åˆä¸­å›½ç¤¾äº¤åª’ä½“å¹³å°çš„æ ¼å¼ã€‚

ã€åŸå§‹å†…å®¹ã€‘
å¹³å°ï¼š${platform}
ä½œè€…ï¼š@${author}
å†…å®¹ï¼š${text}
${metrics.views ? `çƒ­åº¦ï¼š${metrics.views}æµè§ˆ` : ''}
${metrics.upvotes ? `çƒ­åº¦ï¼š${metrics.upvotes}é¡¶` : ''}
é“¾æ¥ï¼š${url}

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆæ³¨æ„ï¼štagså¿…é¡»æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¸è¦åœ¨æ•°ç»„ä¸­ä½¿ç”¨#ç¬¦å·ï¼‰ï¼š
{
  "xiaohongshu": {
    "title": "å¸å¼•äººçš„å°çº¢ä¹¦æ ‡é¢˜ï¼ˆå¸¦emojiï¼‰",
    "content": "å°çº¢ä¹¦é£æ ¼æ­£æ–‡ï¼ˆemoji + ç§è‰è¯­æ°”ï¼‰",
    "tags": ["OpenClaw", "AIå·¥å…·", "çƒ­é—¨"]
  },
  "douyin": {
    "title": "æŠ–éŸ³çŸ­æ ‡é¢˜ï¼ˆæœ‰æ‚¬å¿µæ„Ÿï¼‰",
    "content": "çŸ­è§†é¢‘è„šæœ¬é£æ ¼ï¼ˆç®€æ´æœ‰åŠ›ï¼‰",
    "tags": ["OpenClaw", "AI"]
  },
  "kuaishou": {
    "title": "å¿«æ‰‹é£æ ¼æ ‡é¢˜ï¼ˆæ¥åœ°æ°”ï¼‰",
    "content": "å¿«æ‰‹é£æ ¼æ­£æ–‡ï¼ˆç®€å•ç›´æ¥ï¼‰",
    "tags": ["OpenClaw", "AI"]
  },
  "recommendationScore": 85
}

é‡è¦ï¼š
1. åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹
2. tagsæ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¸è¦åŠ #ç¬¦å·
3. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸è§£æ`;
  }

  /**
   * è°ƒç”¨ GLM-4 API
   */
  private async callGLM(prompt: string): Promise<string> {
    const baseUrl = this.config.baseUrl || 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

    const response = await fetch(baseUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.config.apiKey}`,
      },
      body: JSON.stringify({
        model: 'glm-4-plus',
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.7,
        max_tokens: 2000,
      }),
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`GLM API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }

  /**
   * è°ƒç”¨ Anthropic API
   */
  private async callAnthropic(prompt: string): Promise<string> {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': this.config.apiKey,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 2000,
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
      }),
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Anthropic API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return data.content[0].text;
  }

  /**
   * è§£æ AI å“åº”
   */
  private parseResponse(response: string, rawContent: any): ProcessedContent {
    // å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
    let jsonStr = response;
    const codeBlockMatch = response.match(/```(?:json)?\s*([\s\S]*?)```/);
    if (codeBlockMatch) {
      jsonStr = codeBlockMatch[1];
    }

    // æ¸…ç† JSON å­—ç¬¦ä¸²ï¼Œç§»é™¤æ ‡ç­¾ä¸­çš„ # ç¬¦å·ï¼ˆå¸¸è§çš„ GLM è¾“å‡ºé—®é¢˜ï¼‰
    jsonStr = jsonStr.replace(/#([^\s"\],])/g, '"$1');

    let aiData: any;
    try {
      aiData = JSON.parse(jsonStr);
    } catch (error) {
      // å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤å¸¸è§çš„ JSON é”™è¯¯
      console.warn('JSON parse error, attempting to fix...');

      // ç§»é™¤å°¾éšé€—å·
      jsonStr = jsonStr.replace(/,(\s*[}\]])/g, '$1');

      // ç§»é™¤æ³¨é‡Š
      jsonStr = jsonStr.replace(/\/\/.*$/gm, '');

      // å†æ¬¡å°è¯•è§£æ
      try {
        aiData = JSON.parse(jsonStr);
      } catch (error2) {
        // å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        console.warn('Could not parse AI response, using fallback');
        aiData = this.createFallbackContent(rawContent);
      }
    }

    // æå–æ ‡é¢˜
    const title = rawContent.title || rawContent.text?.split('\n')[0]?.substring(0, 50) || '';

    return {
      original: {
        title,
        text: rawContent.text || '',
        url: rawContent.url || '',
        author: rawContent.author?.username || '',
      },
      xiaohongshu: aiData.xiaohongshu || this.createFallbackFormat(rawContent, 'xiaohongshu'),
      douyin: aiData.douyin || this.createFallbackFormat(rawContent, 'douyin'),
      kuaishou: aiData.kuaishou || this.createFallbackFormat(rawContent, 'kuaishou'),
      recommendationScore: aiData.recommendationScore || 70,
    };
  }

  /**
   * åˆ›å»ºå¤‡ç”¨å†…å®¹ï¼ˆå½“ AI è§£æå¤±è´¥æ—¶ï¼‰
   */
  private createFallbackContent(rawContent: any): any {
    return {
      xiaohongshu: this.createFallbackFormat(rawContent, 'xiaohongshu'),
      douyin: this.createFallbackFormat(rawContent, 'douyin'),
      kuaishou: this.createFallbackFormat(rawContent, 'kuaishou'),
      recommendationScore: 70,
    };
  }

  /**
   * åˆ›å»ºå¤‡ç”¨æ ¼å¼ï¼ˆå½“ AI è§£æå¤±è´¥æ—¶ï¼‰
   */
  private createFallbackFormat(content: any, platform: 'xiaohongshu' | 'douyin' | 'kuaishou'): any {
    const text = content.text || '';
    const author = content.author?.username || '';
    const url = content.url || '';

    if (platform === 'xiaohongshu') {
      return {
        title: `ğŸ”¥å…³äºOpenClawçš„è®¨è®ºæ¥äº†ï¼`,
        content: `å…³äºOpenClawçš„çƒ­é—¨è®¨è®ºï¼š\n\n${text.substring(0, 200)}...\n\næ¥æº: @${author}\n\n#OpenClaw #AIå·¥å…· #çƒ­é—¨è®¨è®º`,
        tags: ['#OpenClaw', '#AIå·¥å…·', '#çƒ­é—¨è®¨è®º'],
      };
    } else if (platform === 'douyin') {
      return {
        title: `å…³äºOpenClawçš„çƒ­é—¨è®¨è®ºï¼`,
        content: `å…³äºOpenClawï¼š\n${text.substring(0, 150)}...`,
        tags: ['#OpenClaw', '#AIå·¥å…·', '#çƒ­é—¨'],
      };
    } else {
      return {
        title: `OpenClawçƒ­é—¨è®¨è®º`,
        content: `${text.substring(0, 100)}...`,
        tags: ['#OpenClaw', '#AI'],
      };
    }
  }
}
